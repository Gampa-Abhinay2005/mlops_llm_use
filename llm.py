"""Module for interacting with the AI Travel Assistant.

Uses the Ollama language model to handle natural language queries.
"""


import httpx
from langchain.llms import Ollama
from langchain_core.exceptions import OutputParserException
from loguru import logger

from logging_client import setup_logger

setup_logger()

llm = Ollama(
    model="llama3",
    temperature=0.7,
    top_p=0.95,
    top_k=40,
    repeat_penalty=1.1,
    num_predict=256,
)

def ask_travel_assistant(question: str) -> str:
    """Process a user question using the LLM-based travel assistant.

    Args:
        question (str): The user's travel-related question.

    Returns:
        str: The response generated by the language model.

    """
    try:
        logger.info(f"Received question: {question}")
        response = llm.invoke(question)
        logger.info(f"Response: {response}")
        return response
    except (httpx.RequestError, OutputParserException):
        logger.exception("Error while invoking travel assistant")
        return "Sorry, an error occurred while processing your request."
